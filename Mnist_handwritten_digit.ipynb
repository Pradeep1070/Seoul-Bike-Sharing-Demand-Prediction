{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAD0GqT02hxQpFcp9j23fD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pradeep1070/Seoul-Bike-Sharing-Demand-Prediction/blob/main/Mnist_handwritten_digit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "sDGB4_DCnV2E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "jLfN5XUmL4YM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train,y_train), (X_test,y_test) = keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "8e8EssU6nYVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape\n",
        "X_train[0].shape"
      ],
      "metadata": {
        "id": "9qad2rtQ3IqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xTFlat =  X_train"
      ],
      "metadata": {
        "id": "AnMHCs8HKpJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "_TmwXXcK3OjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.matshow(X_train[1000])"
      ],
      "metadata": {
        "id": "yreAHVV73leo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PreProscess"
      ],
      "metadata": {
        "id": "tedvBqnSL_qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scaling pixel values\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ],
      "metadata": {
        "id": "vrWJ9sRj6FYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_flattened = X_train.reshape(len(X_train),28*28) #2ds of a pixel map into 1d so that we can feed it into a single input layer of networks\n",
        "X_test_flattened = X_test.reshape(len(X_test),28*28)"
      ],
      "metadata": {
        "id": "ga-KN9_u5Pco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_flattened.shape"
      ],
      "metadata": {
        "id": "Xo7DB217Dndq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0]"
      ],
      "metadata": {
        "id": "_JXBy21S6chn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model 1"
      ],
      "metadata": {
        "id": "equEhzACMEFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#sequantial -> layers are to come sequentialy\n",
        "#dense layer - every input connected to every neuron\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Dense(10, input_shape=(784,), activation='sigmoid')\n",
        "                 ])\n",
        "\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(X_train_flattened, y_train, epochs=5)\n",
        "#epoch - no of iterations"
      ],
      "metadata": {
        "id": "6-qZxmLR6xT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sparse categorical crossentropy vs catergorical crossentropy\n",
        "\n",
        " This loss function is commonly employed when dealing with problems where the target variable is categorical (i.e., it takes discrete class labels), and the classes are mutually exclusive.\n",
        "\n",
        "In the case of sparse categorical crossentropy, the target variable is expected to be provided as integers (class indices), rather than one-hot encoded vectors. This is convenient when dealing with a large number of classes, as it avoids the need to explicitly convert class labels into one-hot encoded vectors.\n",
        "\n",
        "The mathematical expression for sparse categorical crossentropy is similar to the standard categorical crossentropy, but it simplifies the process of specifying the target labels."
      ],
      "metadata": {
        "id": "Zd7bGs9jBXmd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "adam is the default choise for optimizers. optimizers optimize back propagation"
      ],
      "metadata": {
        "id": "l-6-SGfxB0bP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adam (Adaptive Moment Estimation):\n",
        "\n",
        "Advantages: Generally performs well across a wide range of tasks. It adapts the learning rates for each parameter individually.\n",
        "Usage: A good default choice when you're unsure which optimizer to use.\n",
        "\n",
        "\n",
        "SGD (Stochastic Gradient Descent):\n",
        "Advantages: Simple and computationally efficient. Can be effective with proper tuning.\n",
        "Usage: Suitable for large datasets and simpler models. May require careful tuning of learning rate.\n",
        "\n",
        "\n",
        "RMSprop (Root Mean Square Propagation):\n",
        "\n",
        "Advantages: Similar to Adam, adapts learning rates. Can be effective in some cases.\n",
        "Usage: Experiment when Adam does not perform well, especially in recurrent neural networks."
      ],
      "metadata": {
        "id": "NAiSNpvTCWVu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test_flattened,y_test)"
      ],
      "metadata": {
        "id": "Jffgg57VBz7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_test_flattened) #predict complete test set. send in a 2d array with one datapoint to predict one datapoint"
      ],
      "metadata": {
        "id": "-EDRuj-dImkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.predict(np.array([X_test_flattened[0]])))\n",
        "\n",
        "print('\\n',type(X_test_flattened[0]))\n",
        "print(type(np.array([X_test_flattened[0]])))"
      ],
      "metadata": {
        "id": "P5WzR887BaZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yPredict = model.predict(X_test_flattened)\n",
        "yPredict[0]"
      ],
      "metadata": {
        "id": "AbQIpC7m00y3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(plt.matshow(X_test[100]))\n",
        "print(np.argmax(yPredict[100]))#get max value"
      ],
      "metadata": {
        "id": "btpZN69F1BSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds=[np.argmax(i) for i in yPredict]\n",
        "\n",
        "cm = tf.math.confusion_matrix(labels=y_test, predictions=preds)"
      ],
      "metadata": {
        "id": "iwyCCxPsSSvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sn\n",
        "\n",
        "plt.figure(figsize=(5,3.5))\n",
        "sn.heatmap(cm, annot=True, fmt='d')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Truth')"
      ],
      "metadata": {
        "id": "2Y4OQmE1T0sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**adding hidden layer**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5tITikieVXN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train_flattened)"
      ],
      "metadata": {
        "id": "euBmXLlGuwcr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2= keras.Sequential([\n",
        "    keras.layers.Dense(500,input_shape=(784,),activation='relu'),\n",
        "    keras.layers.Dense(70,activation='relu'),\n",
        "    keras.layers.Dense(10,activation='sigmoid')\n",
        "])\n",
        "# relu is more efficient and helps to mitigate vanishing  gradient problem\n",
        "# sigmoid, tanh subject to  vanishing gradient\n",
        "# sigmoid commonly used for the final layer of binary classifiers because it gives a probability for each class\n",
        "\n",
        "model2.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "slice=1\n",
        "X_train_flattened_sliced=X_train_flattened[:int(len(X_train_flattened)/slice)]\n",
        "y_train_sliced=y_train[:int(len(y_train)/slice)]\n",
        "\n",
        "model2.fit(X_train_flattened_sliced,y_train_sliced,epochs=5)"
      ],
      "metadata": {
        "id": "wiKkctbZrojY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(X_train_flattened_sliced)"
      ],
      "metadata": {
        "id": "GrnRvTBfwpIw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.predict(X_test_flattened)"
      ],
      "metadata": {
        "id": "rz4eJDyBtJjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (0.2568, 156.359))"
      ],
      "metadata": {
        "id": "I0dHiBq5tsd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Create a synthetic dataset (replace this with your own data)\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_informative=2, n_redundant=10, n_classes=2, random_state=42)\n"
      ],
      "metadata": {
        "id": "mpHouwBL5KqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "D9mhzfwV-Zh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WVFsf0SR-aJz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}